{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "import xarray as xr\n",
    "import cartopy.crs as ccrs\n",
    "from pyresample.geometry import AreaDefinition\n",
    "from pyresample.geometry import GridDefinition\n",
    "from pyresample import image, geometry, load_area, save_quicklook, SwathDefinition, area_def2basemap\n",
    "from pyresample.kd_tree import resample_nearest\n",
    "#from scipy import spatial\n",
    "sys.path.append('../saildrone/subroutines/')\n",
    "from read_routines import read_all_usv, read_one_usv, add_coll_vars,get_filelist_l2p,get_orbital_data_l2p\n",
    "import warnings\n",
    "warnings.simplefilter('ignore') # filter some warning messages\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in All Saildrone cruises downloaded from https://data.saildrone.com/data/sets\n",
    "- 2017 onwards, note that earlier data is going to lack insruments and be poorer data quality in general\n",
    "- For this code I want to develop a routine that reads in all the different datasets and creates a standardized set\n",
    "- It may work best to first read each of the files individually into a dictionary \n",
    "- then go through each dataset finding all variable names\n",
    "- I decided to put all SST into TEMP_CTD_MEAN and same for Salinity so there is a single variable name\n",
    "- this still preserves all the dataset information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_data = 'C:/Users/gentemann/Google Drive/public/2019_saildrone/' #'f:/data/cruise_data/saildrone/saildrone_data/'\n",
    "dir_data_pattern = 'C:/Users/gentemann/Google Drive/public/2019_saildrone/*.nc' \n",
    "\n",
    "dir_out = 'F:/data/cruise_data/saildrone/sss/sss_collocations_8day/'\n",
    "dir_out2 = 'F:/data/cruise_data/saildrone/sss/sss_collocations_8day_nearest/'\n",
    "\n",
    "data_dict = read_all_usv(dir_data_pattern)\n",
    "#data_dict = add_coll_vars(data_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check on lat/lon range, names, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RSS test open\n",
    "#file = 'F:/data/sat_data/smap/SSS/L3/RSS/V4/8day_running/SCI/2016/001/RSS_smap_SSS_L3_8day_running_2016_005_FNL_v04.0.nc'\n",
    "#ds = xr.open_dataset(file)\n",
    "#ds.coords['lon'] = (ds.coords['lon'] + 180) % 360 - 180\n",
    "#ds = ds.sortby(ds.lon)\n",
    "#ds.close()  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collocate SMAP RSS 8day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RSS\n",
    "#get list of all filenames in directory\n",
    "adir = 'F:/data/sat_data/smap/SSS/L3/RSS/V4/8day_running/SCI/**/**/*.nc'\n",
    "files = [x for x in glob(adir)]\n",
    "print('number of file:',len(files))\n",
    "\n",
    "ds = xr.open_mfdataset(files,combine='nested',concat_dim='time')\n",
    "ds.coords['lon'] = (ds.coords['lon'] + 180) % 360 - 180\n",
    "ds = ds.sortby(ds.lon)\n",
    "ds.close()  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collocate using .interp linear interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for iname,name in enumerate(data_dict):\n",
    "    print(iname)\n",
    "    ds_usv = data_dict[name].copy(deep=True)\n",
    "    ds_usv['lat'] = ds_usv.lat.interpolate_na(dim='time',method='linear').ffill(dim='time').bfill(dim='time')\n",
    "    ds_usv['lon'] = ds_usv.lon.interpolate_na(dim='time',method='linear').ffill(dim='time').bfill(dim='time')\n",
    "    tem = ds_usv.lat.ffill(dim='time')\n",
    "    tem = ds_usv.lat.bfill(dim='time')\n",
    "    t1,t2=ds_usv.time.min().data-np.timedelta64(8,'D'),ds_usv.time.max().data+np.timedelta64(8,'D')\n",
    "    x1,x2=ds_usv.lon.min().data,ds_usv.lon.max().data\n",
    "    y1,y2=ds_usv.lat.min().data,ds_usv.lat.max().data\n",
    "    print(t1,t2)\n",
    "    ds_sat = ds.sel(time=slice(t1,t2),lat=slice(y1,y2),lon=slice(x1,x2)).load()   \n",
    "    ds_interp = ds_sat.interp(time=ds_usv.time,lat=ds_usv.lat,lon=ds_usv.lon,method='linear')#.interp(method='nearest')\n",
    "\n",
    "    #add saildrone data to interpolated sat data\n",
    "    ds_interp = ds_interp.reset_coords(names={'lat','lon'})\n",
    "    for var in ds_interp:\n",
    "        ds_usv['sat_'+var]=ds_interp[var]\n",
    "    #output\n",
    "    fout = dir_out+name+'_RSS8dy'+'.nc'\n",
    "    ds_usv.to_netcdf(fout)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collocate using .interp nearest neighbor interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for iname,name in enumerate(data_dict):\n",
    "    print(iname)\n",
    "    ds_usv = data_dict[name].copy(deep=True)\n",
    "    ds_usv['lat'] = ds_usv.lat.interpolate_na(dim='time',method='linear').ffill(dim='time').bfill(dim='time')\n",
    "    ds_usv['lon'] = ds_usv.lon.interpolate_na(dim='time',method='linear').ffill(dim='time').bfill(dim='time')\n",
    "    tem = ds_usv.lat.ffill(dim='time')\n",
    "    tem = ds_usv.lat.bfill(dim='time')\n",
    "    t1,t2=ds_usv.time.min().data-np.timedelta64(8,'D'),ds_usv.time.max().data+np.timedelta64(8,'D')\n",
    "    x1,x2=ds_usv.lon.min().data,ds_usv.lon.max().data\n",
    "    y1,y2=ds_usv.lat.min().data,ds_usv.lat.max().data\n",
    "    print(t1,t2)\n",
    "    ds_sat = ds.sel(time=slice(t1,t2),lat=slice(y1,y2),lon=slice(x1,x2)).load()   \n",
    "    ds_interp = ds_sat.interp(time=ds_usv.time,lat=ds_usv.lat,lon=ds_usv.lon,method='nearest')#.interp(method='nearest')\n",
    "\n",
    "    #add saildrone data to interpolated sat data\n",
    "    ds_interp = ds_interp.reset_coords(names={'lat','lon'})\n",
    "    for var in ds_interp:\n",
    "        ds_usv['sat_'+var]=ds_interp[var]\n",
    "    #output\n",
    "    fout = dir_out2+name+'_RSS8dy'+'.nc'\n",
    "    ds_usv.to_netcdf(fout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collocation SMAP JPL 8day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#JPL\n",
    "adir = 'F:/data/sat_data/smap/SSS/L3/JPL/V4.3/8day_running/**/**/*4.3.nc'\n",
    "files = [x for x in glob(adir)]\n",
    "print('number of file:',len(files))\n",
    "\n",
    "ds = xr.open_mfdataset(files,combine='nested',concat_dim='time')\n",
    "ds = ds.rename({'latitude':'lat','longitude':'lon'})\n",
    "ds = ds.sortby(ds.lat)\n",
    "ds.close()  \n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for iname,name in enumerate(data_dict):\n",
    "    print(iname)\n",
    "    ds_usv = data_dict[name].copy(deep=True)\n",
    "    ds_usv['lat'] = ds_usv.lat.interpolate_na(dim='time',method='linear').ffill(dim='time').bfill(dim='time')\n",
    "    ds_usv['lon'] = ds_usv.lon.interpolate_na(dim='time',method='linear').ffill(dim='time').bfill(dim='time')\n",
    "    tem = ds_usv.lat.ffill(dim='time')\n",
    "    tem = ds_usv.lat.bfill(dim='time')\n",
    "    t1,t2=ds_usv.time.min().data-np.timedelta64(8,'D'),ds_usv.time.max().data+np.timedelta64(8,'D')\n",
    "    x1,x2=ds_usv.lon.min().data,ds_usv.lon.max().data\n",
    "    y1,y2=ds_usv.lat.min().data,ds_usv.lat.max().data\n",
    "    print(t1,t2)\n",
    "    ds_sat = ds.sel(time=slice(t1,t2),lat=slice(y1,y2),lon=slice(x1,x2)).load()   \n",
    "    ds_interp = ds_sat.interp(time=ds_usv.time,lat=ds_usv.lat,lon=ds_usv.lon,method='linear')#.interp(method='nearest')\n",
    "    #add saildrone data to interpolated sat data\n",
    "    ds_interp = ds_interp.reset_coords(names={'lat','lon'})\n",
    "    for var in ds_interp:\n",
    "        ds_usv['sat_'+var]=ds_interp[var]\n",
    "    \n",
    "    fout = dir_out+name+'_JPL8dy'+'.nc'\n",
    "    ds_usv.to_netcdf(fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for iname,name in enumerate(data_dict):\n",
    "    print(iname)\n",
    "    ds_usv = data_dict[name].copy(deep=True)\n",
    "    ds_usv['lat'] = ds_usv.lat.interpolate_na(dim='time',method='linear').ffill(dim='time').bfill(dim='time')\n",
    "    ds_usv['lon'] = ds_usv.lon.interpolate_na(dim='time',method='linear').ffill(dim='time').bfill(dim='time')\n",
    "    tem = ds_usv.lat.ffill(dim='time')\n",
    "    tem = ds_usv.lat.bfill(dim='time')\n",
    "    t1,t2=ds_usv.time.min().data-np.timedelta64(8,'D'),ds_usv.time.max().data+np.timedelta64(8,'D')\n",
    "    x1,x2=ds_usv.lon.min().data,ds_usv.lon.max().data\n",
    "    y1,y2=ds_usv.lat.min().data,ds_usv.lat.max().data\n",
    "    print(t1,t2)\n",
    "    ds_sat = ds.sel(time=slice(t1,t2),lat=slice(y1,y2),lon=slice(x1,x2)).load()   \n",
    "    ds_interp = ds_sat.interp(time=ds_usv.time,lat=ds_usv.lat,lon=ds_usv.lon,method='nearest')#.interp(method='nearest')\n",
    "    #add saildrone data to interpolated sat data\n",
    "    ds_interp = ds_interp.reset_coords(names={'lat','lon'})\n",
    "    for var in ds_interp:\n",
    "        ds_usv['sat_'+var]=ds_interp[var]\n",
    "    fout = dir_out2+name+'_JPL8dy'+'.nc'\n",
    "    ds_usv.to_netcdf(fout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# remove repeats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'F:/data/cruise_data/saildrone/sss/sss_collocations_8day_nearest/'\n",
    "data_dir_out = 'F:/data/cruise_data/saildrone/sss/sss_collocations_8day_nearest_norepeat/'\n",
    "filenames = [x for x in glob(data_dir+'*.nc')]\n",
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(filenames[1])\n",
    "ds = xr.open_dataset(filenames[1])\n",
    "ds.close()\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc=['lat','lon']\n",
    "for iname,name in enumerate(filenames):\n",
    "    print(iname,len(filenames))\n",
    "    i = name.find('\\\\')\n",
    "    fout = data_dir_out + name[i+1:-3]+'norep.nc' \n",
    "    ds = xr.open_dataset(name)\n",
    "    ds.close()\n",
    "    if 'RSS' in name:  \n",
    "        ds_tem2 = ds.where((ds.sat_sss_smap<50) & (ds.sat_sss_smap>1),drop=True)    \n",
    "        isv=0\n",
    "        while len(ds_tem2.time)>1:\n",
    "            i=0\n",
    "            cond = ((ds_tem2.sat_sss_smap==ds_tem2.sat_sss_smap[i]) \n",
    "                    & (ds_tem2.sat_sss_smap_uncertainty==ds_tem2.sat_sss_smap_uncertainty[i]) \n",
    "                    & (ds_tem2.sat_sss_smap_40km==ds_tem2.sat_sss_smap_40km[i]))\n",
    "            subset = ds_tem2.where(cond,drop=True)  #repeat obs\n",
    "            ds_mn = subset.mean(keep_attrs=True,skipna=True)\n",
    "            ds_mn['time'] = subset.time.mean()\n",
    "            ds_mn = ds_mn.assign_coords({'ob':isv})\n",
    "            if isv==0:\n",
    "                ds_mn2 = ds_mn\n",
    "            else:\n",
    "                ds_mn2 = xr.concat([ds_mn2,ds_mn],dim='ob')\n",
    "            isv = isv+1\n",
    "            ds_tem2 = ds_tem2.where(~cond,drop=True)  #data with repeat obs removed\n",
    "    else:\n",
    "        ds_tem2 = ds.where((ds.sat_smap_sss<50) & (ds.sat_smap_sss>1),drop=True)    \n",
    "        isv=0\n",
    "        while len(ds_tem2.time)>1:\n",
    "            i=0\n",
    "            cond = ((ds_tem2.sat_smap_sss==ds_tem2.sat_smap_sss[i]) \n",
    "                    & (ds_tem2.sat_anc_sst==ds_tem2.sat_anc_sst[i]) \n",
    "                    & (ds_tem2.sat_anc_sss==ds_tem2.sat_anc_sss[i]))\n",
    "            subset = ds_tem2.where(cond,drop=True)  #repeat obs\n",
    "            ds_mn = subset.mean(keep_attrs=True,skipna=True)\n",
    "            ds_mn['time'] = subset.time.mean()\n",
    "            ds_mn = ds_mn.assign_coords({'ob':isv})\n",
    "            if isv==0:\n",
    "                ds_mn2 = ds_mn\n",
    "            else:\n",
    "                ds_mn2 = xr.concat([ds_mn2,ds_mn],dim='ob')\n",
    "            isv = isv+1\n",
    "            ds_tem2 = ds_tem2.where(~cond,drop=True)  #data with repeat obs removed\n",
    "    ds_mn2.to_netcdf(fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'F:/data/cruise_data/saildrone/sss/sss_collocations_8day_nearest/saildrone-gen_5-arctic_misst_2019-sd1036-20190514T230000-20191011T183000-1_minutes-v1.1575336154680_JPL8dy.nc'\n",
    "ds_tem = xr.open_dataset(fname)\n",
    "plt.plot(ds_tem.lon,ds.lat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fix remove RSS data from JPL collocation\n",
    "ds = ds.drop({'sat_nobs','sat_nobs_40km','sat_sss_smap','sat_sss_smap_uncertainty','sat_sss_smap_40km','sat_sss_ref','sat_gland','sat_fland','sat_gice','sat_surtep'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_interp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_usv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ds_usv.time,ds_usv.SAL_CTD_MEAN,'b')\n",
    "plt.plot(ds_usv.time,ds_usv.sat_smap_sss,'r.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tem = ds.sel(time='2019-08-01',lat=slice(30,55),lon=slice(-130,-110))\n",
    "plt.pcolormesh(tem.lon,tem.lat,tem.smap_sss[0,:,:])\n",
    "plt.plot(ds_usv.lon,ds_usv.lat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "file = 'F:/data/cruise_data/saildrone/sss/sss_collocations_8day_nearest/saildrone-gen_5-atomic_eurec4a_2020-sd1026-20200117T000000-20200302T235959-1_minutes-v1.1589306725934_JPL8dy.nc'\n",
    "ds = xr.open_dataset(file)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for name in data_dict:\n",
    "#    print(name)\n",
    "ds2 = data_dict['saildrone-gen_5-atomic_eurec4a_2020-sd1026-20200117T000000-20200302T235959-1_minutes-v1.1589306725934']\n",
    "ds2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_list = ['F:/data/cruise_data/saildrone/sss/sss_collocations_8day/',\n",
    "        'F:/data/cruise_data/saildrone/sss/sss_collocations_8day_nearest/',\n",
    "        'F:/data/cruise_data/saildrone/sss/sss_collocations_8day_nearest_norepeat/']\n",
    "files = glob(dir_list[0]+'*.nc')\n",
    "file = files[2]\n",
    "#if 'JPL' in file:\n",
    "print(file)\n",
    "ds = xr.open_dataset(file)\n",
    "ds.close()\n",
    "#ds = ds.drop({'sat_nobs','sat_nobs_40km','sat_sss_smap','sat_sss_smap_uncertainty','sat_sss_smap_40km','sat_sss_ref','sat_gland','sat_fland','sat_gice','sat_surtep' })\n",
    "print(ds)\n",
    "#ds.to_netcdf(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
